{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6e12e82",
   "metadata": {},
   "source": [
    "# 0. Import Data (v.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a369e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HC - Hardcoded; not ideal\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import os\n",
    "import numpy\n",
    "\n",
    "wave_path = r'C:\\Users\\olusa\\Documents\\VS Code\\ML\\MVP\\Gestures\\Wave' # HC\n",
    "all_files_in_wave = glob.glob(os.path.join(wave_path, \"*.csv\"))\n",
    "\n",
    "wave_X = numpy.zeros((len(all_files_in_wave),200,6)) # HC num examples x num samples per example x num inputs\n",
    "\n",
    "csvIndex = 0\n",
    "for csv in all_files_in_wave:\n",
    "    wave_X[csvIndex] = pd.read_csv(csv)\n",
    "    csvIndex += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cbb72b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_path = r'C:\\Users\\olusa\\Documents\\VS Code\\ML\\MVP\\Gestures\\Noise' # HC\n",
    "all_files_in_noise = glob.glob(os.path.join(noise_path, \"*.csv\"))\n",
    "\n",
    "noise_X = numpy.zeros((len(all_files_in_noise),200,6)) # HC\n",
    "\n",
    "csvIndex = 0\n",
    "for csv in all_files_in_noise:\n",
    "    noise_X[csvIndex] = pd.read_csv(csv)\n",
    "    csvIndex += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "809cac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numpy.concatenate([noise_X, wave_X]) # HC\n",
    "# print (X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d09b83ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_y = numpy.zeros(len(all_files_in_wave)) # HC\n",
    "noise_y = numpy.ones(len(all_files_in_noise)) # HC\n",
    "\n",
    "y = numpy.concatenate([noise_y, wave_y]) # HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "813bf37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb5239da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 200, 6) (4, 200, 6)\n",
      "[1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a16f3a",
   "metadata": {},
   "source": [
    "# 0. Import Data (v.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20cb7873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 200, 6)\n"
     ]
    }
   ],
   "source": [
    "# HC - Hardcoded; not ideal\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import os\n",
    "import numpy\n",
    "\n",
    "# Sample config vars\n",
    "num_readings_per_sample = 200\n",
    "num_values_per_reading = 6\n",
    "\n",
    "# Wave dataframe import\n",
    "wave_df = pd.read_csv('./Gestures/Wave2/waves.csv')\n",
    "# wave_df.head()\n",
    "# print(len(wave_df))\n",
    "\n",
    "# Separating samples into 3D Matrix, wave_X\n",
    "num_samples_in_wave_df = int(len(wave_df) / num_readings_per_sample)\n",
    "\n",
    "## Init wave_X\n",
    "wave_X = numpy.zeros((num_samples_in_wave_df, num_readings_per_sample, num_values_per_reading))\n",
    "\n",
    "layerIndex = 0\n",
    "for sampleLayer in wave_X:\n",
    "    first_row_index = layerIndex * num_readings_per_sample\n",
    "    last_row_index = (layerIndex * num_readings_per_sample) + num_readings_per_sample\n",
    "    wave_X[layerIndex] = wave_df.iloc[first_row_index:last_row_index, :]\n",
    "    layerIndex += 1\n",
    "\n",
    "print(wave_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b107dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numpy.concatenate([wave_X]) # HC\n",
    "# print (X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c2d5c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_y = numpy.ones(num_samples_in_wave_df) # HC\n",
    "\n",
    "y = numpy.concatenate([wave_y]) # HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "115fe591",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a22bbb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 200, 6) (4, 200, 6)\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658eb86c",
   "metadata": {},
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b90c9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c05fa2",
   "metadata": {},
   "source": [
    "# 2. Build and Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffcd7842",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten(input_shape=(num_readings_per_sample, num_values_per_reading)))\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "081558da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f52f12",
   "metadata": {},
   "source": [
    "# 3. Fit, Predict and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8a597e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 10.2170 - accuracy: 0.8125\n",
      "Epoch 2/4\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.7391 - accuracy: 0.9375\n",
      "Epoch 3/4\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 3.5754e-15 - accuracy: 1.0000\n",
      "Epoch 4/4\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 3.5754e-15 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x272f5a26dc0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=4, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e39ee3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "tflite_quant_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "891037b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "y_hat = [0 if val <0.5 else 1 for val in y_hat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0101909a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959c4562",
   "metadata": {},
   "source": [
    "# 4. Save and Convert to TFLite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3aad8341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\olusa\\anaconda3\\envs\\python2\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\olusa\\anaconda3\\envs\\python2\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72f16931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2432"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"converted_model.tflite\", \"wb\").write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defbf72d",
   "metadata": {},
   "source": [
    "# Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9969f848",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "# from keras.models import model_from_json\n",
    "# serialize model to json\n",
    "json_model = model.to_json()\n",
    "#save the model architecture to JSON file\n",
    "with open('model.json', 'w') as json_file:\n",
    "    json_file.write(json_model)\n",
    "#saving the weights of the model\n",
    "model.save_weights('model_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
